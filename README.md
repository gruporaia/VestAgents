# VestAgents

Welcome to VestAgents! This project aims to create a tool for generating original entrance-exam questions for Brazilian vestibular exams using Large Language Models (LLMs). The development is supported by the distance-education company [PICO](https://www.usepico.com.br/) and explores alternatives to the company‚Äôs existing question-generation tool.

We implement 4 strategies:
- **Retrieval-generator**: A system with inbuilt RAG (Retrieval-Augmented Generation) to search for relevant questions.
- **Few-shot**: A system employing a Few-Shot Prompt generator using the 5 most relevant questions.
- **Scraping**: Searches for data on the web to include as guiding text.
- **Paired Crew**: A crew employing both web scraping and the few-shot approach.

## Retrieval-generator:

Instead of relying solely on the LLM's internal knowledge, our tool enables an AI agent to consult past exam questions before creating a new one. This consultation is performed on a specialized database containing thousands of questions, previously cataloged by knowledge area (e.g., Mathematics, Physics) and subcategory (e.g., Kinematics, Thermodynamics).

### Solution Architecture: RAG with Similarity Search

To allow the AI agent to "search" through a text-based database, we implemented a similarity search system. The process works in two main stages: **creating a vector knowledge base** and **retrieving relevant information** in real-time.

![Rag Agent Flowchart](assets/flowchart_rag_agent_en.png)

#### 1. Embeddings: Converting Text into Vectors

The first step was to transform our entire collection of exam questions into a format that a computer could understand and numerically compare. To do this, we used a technique called **embeddings**.

* **What are Embeddings?** üß†
    An embedding model is a neural network that converts words, sentences, or entire documents into high-dimensional numerical vectors. The key advantage of this technique is that the generated vectors capture the **semantic meaning** of the text. This means that questions with similar topics or concepts, even if written with different words, will have very close vector representations in the vector space.

#### 2. Vector Store and FAISS: Efficient Storage and Search

Once all the questions were converted into embeddings, the next challenge was to store and search them efficiently. This is where vector stores and the FAISS library come in.

* **What is a Vector Store?** üóÑÔ∏è
    A vector store (or vector database) is a type of database specifically optimized for storing and querying embedding vectors. Unlike a traditional database that searches for exact text matches, a vector store finds the vectors closest to a query vector, performing a **similarity search**.

* **How does FAISS work?** ‚ö°
    To manage our vector store, we use the **FAISS (Facebook AI Similarity Search)** library. FAISS is a highly efficient open-source library for similarity search in dense sets of vectors. It creates a data structure (an index) that organizes the question vectors for optimal performance. When a user requests a new question, we first convert that request into an embedding vector. Then, we use FAISS to rapidly compare this vector against the millions of indexed question vectors, returning the most similar ones in milliseconds.

#### 3. Multi-Index Strategy

To improve the relevance of our search results, we did not just create a single index. Instead, we generated separate embeddings and vector stores for different aspects of the questions:

* **Raw Text Embeddings:** Allow finding questions with similar conceptual content.
* **Category and Subcategory Embeddings:** Help refine the search, ensuring that the retrieved examples belong to the correct knowledge area as requested by the user.

---

### Generation Flow

With this architecture, the AI agent responsible for creating questions follows an intelligent workflow:

1.  **Receives the Request:** The user specifies the topic for the desired question (e.g., "a question about Newton's Second Law").
2.  **Similarity Search:** The tool converts the request into an embedding and uses FAISS to search its vector store for the most semantically similar questions.
3.  **Contextualization:** The retrieved questions (e.g., 5 examples of questions about Newton's Laws) are provided to the LLM as context or "reference examples."
4.  **Augmented Generation:** Based on these high-quality examples, the LLM generates a **new and original question** that follows the style, difficulty, and format of real university entrance exam questions on that topic.

## Few-shot

This system makes use of a RAG-based tool to perform a few-shot approach to generate new questions. Instead of relying solely on the LLM's internal knowledge, our tool enables an AI agent to consult the 5 past exam questions most related to the user's prompt so that a new question can be created. This consultation is performed on a specialized database containing thousands of questions, previously cataloged by knowledge area (e.g., Mathematics, Physics) and subcategory (e.g., Kinematics, Thermodynamics).

The architecture is similar to the Retrieval-generator model, only changing the generation flow to include a post-process of the retrieval to generate a few-shot prompt. This is spread by separating the flow into two crews, where the second one gets the outputs from the previous one and embeds the few-shot prompt into the generator agent.

### Generation Flow

With this architecture, the AI agent responsible for creating questions follows an intelligent workflow:

1.  **Receives the Request:** The user specifies the topic for the desired question (e.g., "a question about Newton's Second Law").
2.  **Similarity Search:** The tool converts the request into an embedding and uses FAISS to search its vector store for the most semantically similar questions.
3.  **Contextualization:** The retrieved questions (e.g., 5 examples of questions about Newton's Laws) are provided to the LLM as context or "reference examples."
4.  **Augmented Generation:** Based on these high-quality examples, the LLM generates a **new and original question** that follows the style, difficulty, and format of real university entrance exam questions on that topic.

## Scraping

This system implements a **Web Scraping‚Äìbased** approach. Instead of relying solely on the LLM‚Äôs internal knowledge, our tool allows an AI agent to query specialized websites on topics covered in traditional Brazilian vestibular exams. We perform searches via the Serper API to find the most relevant sites and then use Beautiful Soup to extract the HTML content, which provides the contextual text for our question-generation agent.

---

### 1. Preparation

The process has two main stages: **Searching for specialized sites** and **Extracting content**. An upstream agent first analyzes the user‚Äôs prompt to identify relevant details‚Äîsuch as subject and subtopic‚Äîneeded to guide the search. For example:

```

I want to generate mathematics questions on probability for S√£o Paulo vestibular exams

````

Here, the agent would extract **Mathematics** as the subject and **Probability** as the subtopic, then pass those parameters into the Web Scraping pipeline.

### 2. Web Search with Serper

**Serper** is a programmatic search API that returns structured JSON‚Äîtitles, snippets, URLs, and metadata‚Äîinstead of raw HTML meant for browsers. This allows fast, secure, and easily integrated searches into our Web Scraping pipeline.

Example usage in our agent:
```python
@agent
def search_and_extract(self) -> Agent:
    return Agent(
        config=self.agents_config['search_and_extract'],
        tools=[SerperDevTool(), RawParagraphTool()],
        verbose=True,
        memory=True
    )
````

A typical Serper API response looks like:

```json
{
  "title": "Oxidation Reactions ‚Äì Organic Chemistry | Example.edu",
  "snippet": "In organic chemistry, oxidation is defined as ‚Ä¶",
  "link": "[https://example.edu/oxidation](https://example.edu/oxidation)",
  "displayed_link": "example.edu"
}
```

Once we have these URLs, we feed them to Beautiful Soup to fetch and parse the raw HTML.

### 3\. Content Extraction with Beautiful Soup

**What is Beautiful Soup?** ü•£
Beautiful Soup is a Python library for parsing HTML and XML. It converts an HTML string into a tree of Python objects, making it easy to locate and extract specific elements without wrestling with regex or brittle DOM parsing.

**How we use it in VestAgents:**

1.  **Load the HTML**
    After retrieving the raw HTML (via `web.open`), we instantiate Beautiful Soup:
    ```python
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html_content, 'html.parser')
    ```
2.  **Extract Paragraphs**
    We collect all `<p>` tags:
    ```python
    paragraphs = [str(p) for p in soup.find_all("p")]
    ```
    This yields a list of strings, each preserving the original HTML markup, accents, and formatting.
3.  **Pipeline Integration**
    These paragraphs are supplied to the `search_and_extract` agent, which determines which snippets are most relevant to serve as ‚Äúcontextual passages‚Äù for the question-generation agent. By preserving the original structure of each paragraph, we ensure fidelity to the source material.

-----

Below is a diagram showing how this approach fits into our overall architecture:

1.  **Receive Request**: The user specifies the desired question topic (e.g., ‚Äúa math question on probability‚Äù).
2.  **Prompt Refinement**: Intermediate agents refine the initial prompt to identify subject and subtopic (e.g., ‚ÄúMathematics | Probability‚Äù).
3.  **Search & Extraction**: We query specialized sites and extract relevant text for context.
4.  **Question Generation**: Using the user‚Äôs request and the extracted passages, an agent generates a tailored vestibular-style question.

## Paired Crew

This strategy first implements the few-shot builder agent, then a second crew executes the web scraping agent, and finally merges both results to generate a new question.

-----

# Installation

Ensure you have Python **3.10‚Äì3.12** installed. This project uses [UV](https://docs.astral.sh/uv/) for dependency and package management, giving you a smooth setup and run experience.

First, if you don‚Äôt already have it, install UV:

```bash
pip install uv
```

Then, from the project root, install dependencies:

```bash
crewai install
```

### Customization

1.  Add your `OPENAI_API_KEY` to a `.env` file.
2.  Modify `src/raia_agents/config/agents.yaml` to configure your agents.
3.  Modify `src/raia_agents/config/tasks.yaml` to define tasks.
4.  Update `src/raia_agents/crew.py` to add custom logic, tools, or arguments.
5.  Update `src/raia_agents/main.py` to include custom inputs for your agents and tasks.

### Running the Project

To start your AI agent crew and execute tasks, run:

```bash
crewai run
```

This command initializes the `raia_agents` crew and dispatches agents according to your configuration.

-----

-----

# VestAgents

Bem-vindo ao VestAgents\! Este projeto visa criar uma ferramenta de gera√ß√£o de quest√µes in√©ditas para vestibulares brasileiros utilizando Modelos de Linguagem Grandes (LLMs). O desenvolvimento conta com o apoio da empresa de educa√ß√£o a dist√¢ncia [PICO](https://www.usepico.com.br/) e explora alternativas para a ferramenta de gera√ß√£o de quest√µes existente na empresa.

Implementamos 4 estrat√©gias:

  - **Retrieval-generator**: Um sistema com busca RAG (Gera√ß√£o Aumentada por Recupera√ß√£o) integrada para pesquisar quest√µes relevantes.
  - **Few-shot**: Um sistema que emprega um gerador de Prompts Few-Shot usando as 5 quest√µes mais relevantes.
  - **Scraping**: Realiza buscas na web para incluir dados como texto de apoio.
  - **Paired Crew**: Uma equipe que emprega tanto a web scraping quanto a abordagem few-shot.

## Retrieval-generator:

Em vez de depender apenas do conhecimento interno do LLM, nossa ferramenta permite que um agente de IA consulte quest√µes de vestibulares anteriores antes de criar uma nova. Essa consulta √© realizada em um banco de dados especializado que cont√©m milhares de quest√µes, previamente catalogadas por √°rea de conhecimento (ex: Matem√°tica, F√≠sica) e subcategoria (ex: Cinem√°tica, Termodin√¢mica).

### Arquitetura da Solu√ß√£o: RAG com Busca por Similaridade

Para permitir que o agente de IA "pesquise" em um banco de dados textual, implementamos um sistema de busca por similaridade. O processo funciona em duas etapas principais: **cria√ß√£o de uma base de conhecimento vetorial** e **recupera√ß√£o de informa√ß√µes relevantes** em tempo real.

#### 1\. Embeddings: Convertendo Texto em Vetores

O primeiro passo foi transformar toda a nossa cole√ß√£o de quest√µes de vestibular em um formato que um computador pudesse entender e comparar numericamente. Para isso, usamos uma t√©cnica chamada **embeddings**.

  * **O que s√£o Embeddings?** üß†
    Um modelo de embedding √© uma rede neural que converte palavras, frases ou documentos inteiros em vetores num√©ricos de alta dimens√£o. A principal vantagem dessa t√©cnica √© que os vetores gerados capturam o **significado sem√¢ntico** do texto. Isso significa que quest√µes com t√≥picos ou conceitos similares, mesmo que escritas com palavras diferentes, ter√£o representa√ß√µes vetoriais muito pr√≥ximas no espa√ßo vetorial.

#### 2\. Vector Store e FAISS: Armazenamento e Busca Eficiente

Depois que todas as quest√µes foram convertidas em embeddings, o pr√≥ximo desafio era armazen√°-las e pesquis√°-las de forma eficiente. √â aqui que entram os vector stores e a biblioteca FAISS.

  * **O que √© um Vector Store?** üóÑÔ∏è
    Um vector store (ou banco de dados vetorial) √© um tipo de banco de dados otimizado especificamente para armazenar e consultar vetores de embedding. Diferente de um banco de dados tradicional que busca por correspond√™ncias exatas de texto, um vector store encontra os vetores mais pr√≥ximos a um vetor de consulta, realizando uma **busca por similaridade**.

  * **Como o FAISS funciona?** ‚ö°
    Para gerenciar nosso vector store, usamos a biblioteca **FAISS (Facebook AI Similarity Search)**. FAISS √© uma biblioteca de c√≥digo aberto altamente eficiente para busca por similaridade em conjuntos densos de vetores. Ela cria uma estrutura de dados (um √≠ndice) que organiza os vetores das quest√µes para um desempenho otimizado. Quando um usu√°rio solicita uma nova quest√£o, primeiro convertemos essa solicita√ß√£o em um vetor de embedding. Em seguida, usamos o FAISS para comparar rapidamente esse vetor com milh√µes de vetores de quest√µes indexados, retornando os mais similares em milissegundos.

#### 3\. Estrat√©gia de M√∫ltiplos √çndices

Para melhorar a relev√¢ncia dos nossos resultados de busca, n√£o criamos apenas um √∫nico √≠ndice. Em vez disso, geramos embeddings e vector stores separados para diferentes aspectos das quest√µes:

  * **Embeddings de Texto Bruto:** Permitem encontrar quest√µes com conte√∫do conceitual semelhante.
  * **Embeddings de Categoria e Subcategoria:** Ajudam a refinar a busca, garantindo que os exemplos recuperados perten√ßam √† √°rea de conhecimento correta, conforme solicitado pelo usu√°rio.

-----

### Fluxo de Gera√ß√£o

Com essa arquitetura, o agente de IA respons√°vel por criar as quest√µes segue um fluxo de trabalho inteligente:

1.  **Recebe a Solicita√ß√£o:** O usu√°rio especifica o tema da quest√£o desejada (ex: "uma quest√£o sobre a Segunda Lei de Newton").
2.  **Busca por Similaridade:** A ferramenta converte a solicita√ß√£o em um embedding e usa o FAISS para buscar em seu vector store as quest√µes semanticamente mais similares.
3.  **Contextualiza√ß√£o:** As quest√µes recuperadas (ex: 5 exemplos de quest√µes sobre as Leis de Newton) s√£o fornecidas ao LLM como contexto ou "exemplos de refer√™ncia".
4.  **Gera√ß√£o Aumentada:** Com base nesses exemplos de alta qualidade, o LLM gera uma **quest√£o nova e original** que segue o estilo, a dificuldade e o formato das quest√µes reais de vestibular sobre aquele t√≥pico.

## Few-shot

Este sistema utiliza uma ferramenta baseada em RAG para aplicar uma abordagem few-shot na gera√ß√£o de novas quest√µes. Em vez de depender apenas do conhecimento interno do LLM, nossa ferramenta permite que um agente de IA consulte as 5 quest√µes de vestibulares passados mais relacionadas ao prompt do usu√°rio para que uma nova quest√£o possa ser criada. Essa consulta √© realizada em um banco de dados especializado que cont√©m milhares de quest√µes, previamente catalogadas por √°rea de conhecimento (ex: Matem√°tica, F√≠sica) e subcategoria (ex: Cinem√°tica, Termodin√¢mica).

A arquitetura √© semelhante ao modelo Retrieval-generator, alterando apenas o fluxo de gera√ß√£o, que inclui um p√≥s-processamento da recupera√ß√£o para gerar um prompt few-shot. Isso √© distribu√≠do ao separar o fluxo em duas equipes (crews), onde a segunda recebe os resultados da primeira e incorpora o prompt few-shot no agente gerador.

### Fluxo de Gera√ß√£o

Com essa arquitetura, o agente de IA respons√°vel por criar as quest√µes segue um fluxo de trabalho inteligente:

1.  **Recebe a Solicita√ß√£o:** O usu√°rio especifica o tema da quest√£o desejada (ex: "uma quest√£o sobre a Segunda Lei de Newton").
2.  **Busca por Similaridade:** A ferramenta converte a solicita√ß√£o em um embedding e usa o FAISS para buscar em seu vector store as quest√µes semanticamente mais similares.
3.  **Contextualiza√ß√£o:** As quest√µes recuperadas (ex: 5 exemplos de quest√µes sobre as Leis de Newton) s√£o fornecidas ao LLM como contexto ou "exemplos de refer√™ncia".
4.  **Gera√ß√£o Aumentada:** Com base nesses exemplos de alta qualidade, o LLM gera uma **quest√£o nova e original** que segue o estilo, a dificuldade e o formato das quest√µes reais de vestibular sobre aquele t√≥pico.

## Scraping

Este sistema implementa uma abordagem baseada em **Web Scraping**. Em vez de depender apenas do conhecimento interno do LLM, nossa ferramenta permite que um agente de IA consulte sites especializados em assuntos abordados nos vestibulares tradicionais do Brasil. Realizamos buscas via API Serper para encontrar os sites mais relevantes e, em seguida, usamos o Beautiful Soup para extrair o conte√∫do HTML, que fornece o texto contextual para nosso agente gerador de quest√µes.

-----

### 1\. Prepara√ß√£o

O processo funciona em duas etapas principais: a **Busca de sites especializados** e a **extra√ß√£o de conte√∫do**. Um agente, anterior √† etapa de busca e extra√ß√£o, analisa o prompt do usu√°rio para identificar detalhes relevantes ‚Äî como mat√©ria e subt√≥pico ‚Äî necess√°rios para guiar a busca. Por exemplo:

```
Quero gerar quest√µes de matem√°tica de probabilidade para vestibulares paulistas
```

Aqui, o agente extrairia **Matem√°tica** como a mat√©ria e **Probabilidade** como o subt√≥pico, e ent√£o passaria esses par√¢metros para o pipeline de Web Scraping.

### 2\. Busca na Web com Serper

O **Serper** √© uma API de busca program√°tica que retorna JSON estruturado ‚Äî t√≠tulos, snippets, URLs e metadados ‚Äî em vez de HTML bruto destinado a navegadores. Isso permite buscas r√°pidas, seguras e facilmente integr√°veis ao nosso pipeline de Web Scraping.

Exemplo de uso em nosso agente:

```python
@agent
def pesquisa_e_extracao(self) -> Agent:
    return Agent(
        config=self.agents_config['pesquisa_e_extracao'],
        tools=[SerperDevTool(), RawParagraphTool()],
        verbose=True,
        memory=True
    )
```

Uma resposta t√≠pica da API do Serper se parece com:

```json
{
  "title": "Rea√ß√µes de oxida√ß√£o ‚Äì Qu√≠mica Org√¢nica | Exemplo.edu",
  "snippet": "Na qu√≠mica org√¢nica, oxida√ß√£o √© definida como ...",
  "link": "[https://exemplo.edu/oxidacao](https://exemplo.edu/oxidacao)",
  "displayed_link": "exemplo.edu"
}
```

Assim que temos essas URLs, n√≥s as fornecemos ao Beautiful Soup para buscar e analisar o HTML bruto.

### 3\. Extra√ß√£o de Conte√∫do com Beautiful Soup

  * **O que √© o Beautiful Soup?** ü•£
    O Beautiful Soup √© uma biblioteca Python para fazer parsing de documentos HTML e XML. Ela converte uma string HTML em uma √°rvore de objetos Python, facilitando a localiza√ß√£o e extra√ß√£o de elementos espec√≠ficos sem a necessidade de lidar com regex ou com as particularidades do DOM de cada site.

  * **Como usamos no VestAgents:**

    1.  **Carregar o HTML**
        Ap√≥s obter o HTML bruto (via `web.open`), instanciamos o Beautiful Soup:
        ```python
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        ```
    2.  **Extrair Par√°grafos**
        Coletamos todas as tags `<p>`:
        ```python
        paragraphs = [str(p) for p in soup.find_all("p")]
        ```
        Isso resulta em uma lista de strings, cada uma preservando a marca√ß√£o HTML, acentos e formata√ß√£o originais.
    3.  **Integra√ß√£o ao Pipeline**
        Esses par√°grafos s√£o fornecidos ao agente `pesquisa_e_extracao`, que determina quais trechos s√£o mais relevantes para servir como "passagens de apoio" para o agente de gera√ß√£o de quest√µes. Ao preservar a estrutura original de cada par√°grafo, garantimos fidelidade ao material de origem.

-----

Abaixo, um diagrama mostrando como essa abordagem se encaixa em nossa arquitetura geral:

1.  **Recebe a Solicita√ß√£o**: O usu√°rio especifica o tema da quest√£o desejada (ex: "uma quest√£o de matem√°tica sobre probabilidade").
2.  **Refinamento do Prompt**: Agentes intermedi√°rios refinam o prompt inicial para identificar a mat√©ria e o subt√≥pico (ex: "Matem√°tica | Probabilidade").
3.  **Busca e Extra√ß√£o**: Consultamos sites especializados e extra√≠mos texto relevante para o contexto.
4.  **Gera√ß√£o da Quest√£o**: Usando a solicita√ß√£o do usu√°rio e as passagens extra√≠das, um agente gera uma quest√£o personalizada no estilo vestibular.

## Paired Crew

Esta abordagem implementa primeiro o agente construtor de few-shot, em seguida, para a segunda equipe, executa inicialmente o agente de web scraping e, por fim, mescla ambos os resultados para gerar uma nova quest√£o.

-----

# Instala√ß√£o

Certifique-se de que voc√™ tenha o Python **3.10 a 3.12** instalado. Este projeto utiliza o [UV](https://docs.astral.sh/uv/) para gerenciamento de depend√™ncias e pacotes, oferecendo uma experi√™ncia de configura√ß√£o e execu√ß√£o fluida.

Primeiro, se voc√™ ainda n√£o tiver, instale o UV:

```bash
pip install uv
```

Em seguida, a partir da raiz do projeto, instale as depend√™ncias:

```bash
crewai install
```

### Personaliza√ß√£o

1.  Adicione sua `OPENAI_API_KEY` a um arquivo `.env`.
2.  Modifique `src/raia_agents/config/agents.yaml` para configurar seus agentes.
3.  Modifique `src/raia_agents/config/tasks.yaml` para definir suas tarefas.
4.  Atualize `src/raia_agents/crew.py` para adicionar sua pr√≥pria l√≥gica, ferramentas ou argumentos.
5.  Atualize `src/raia_agents/main.py` para incluir entradas personalizadas para seus agentes e tarefas.

### Executando o Projeto

Para iniciar sua equipe de agentes de IA e executar as tarefas, rode:

```bash
crewai run
```

Este comando inicializa a equipe `raia_agents` e despacha os agentes de acordo com sua configura√ß√£o.
